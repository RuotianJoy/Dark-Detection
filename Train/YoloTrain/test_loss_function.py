"""
æŸå¤±å‡½æ•°æµ‹è¯•è„šæœ¬ - æ£€æŸ¥MultiTaskLosså®ç°
"""

import torch
import torch.nn as nn
import numpy as np
from custom_yolo import MultiTaskLoss, ThermalRegressionHead

def test_multi_task_loss():
    """æµ‹è¯•å¤šä»»åŠ¡æŸå¤±å‡½æ•°"""
    print("=== æµ‹è¯•å¤šä»»åŠ¡æŸå¤±å‡½æ•° ===")
    
    # åˆå§‹åŒ–æŸå¤±å‡½æ•°
    loss_fn = MultiTaskLoss(lambda_temp=1.0, lambda_reg=0.001)
    print(f"âœ“ æŸå¤±å‡½æ•°åˆå§‹åŒ–æˆåŠŸ")
    print(f"  - æ¸©åº¦æŸå¤±æƒé‡: {loss_fn.lambda_temp}")
    print(f"  - æ­£åˆ™åŒ–æƒé‡: {loss_fn.lambda_reg}")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    batch_size = 4
    
    # æ¨¡æ‹ŸYOLOæŸå¤±
    yolo_loss = torch.tensor(2.5, requires_grad=True)
    
    # æ¨¡æ‹Ÿæ¸©åº¦é¢„æµ‹å’ŒçœŸå®å€¼
    pred_temp = torch.randn(batch_size, requires_grad=True)
    gt_temp = torch.randn(batch_size)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„æ¸©åº¦é¢„æµ‹å¤´å‚æ•°
    thermal_head = ThermalRegressionHead(input_channels=1024, hidden_dim=256)
    temp_head_params = list(thermal_head.parameters())
    
    print(f"\næ¨¡æ‹Ÿæ•°æ®:")
    print(f"  - YOLOæŸå¤±: {yolo_loss.item():.4f}")
    print(f"  - é¢„æµ‹æ¸©åº¦: {pred_temp.detach().numpy()}")
    print(f"  - çœŸå®æ¸©åº¦: {gt_temp.numpy()}")
    print(f"  - æ¸©åº¦å¤´å‚æ•°æ•°é‡: {len(temp_head_params)}")
    
    # è®¡ç®—æŸå¤±
    try:
        loss_dict = loss_fn(yolo_loss, pred_temp, gt_temp, temp_head_params)
        
        print(f"\nâœ“ æŸå¤±è®¡ç®—æˆåŠŸ:")
        print(f"  - æ€»æŸå¤±: {loss_dict['total_loss'].item():.4f}")
        print(f"  - YOLOæŸå¤±: {loss_dict['yolo_loss'].item():.4f}")
        print(f"  - æ¸©åº¦æŸå¤±: {loss_dict['temp_loss'].item():.4f}")
        print(f"  - æ­£åˆ™åŒ–æŸå¤±: {loss_dict['reg_loss'].item():.4f}")
        
        # æ£€æŸ¥æ¢¯åº¦
        loss_dict['total_loss'].backward()
        print(f"\nâœ“ åå‘ä¼ æ’­æˆåŠŸ")
        print(f"  - YOLOæŸå¤±æ¢¯åº¦: {yolo_loss.grad}")
        print(f"  - é¢„æµ‹æ¸©åº¦æ¢¯åº¦: {pred_temp.grad is not None}")
        
        return True
        
    except Exception as e:
        print(f"âœ— æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        return False

def test_loss_components():
    """æµ‹è¯•æŸå¤±å‡½æ•°å„ä¸ªç»„ä»¶"""
    print("\n=== æµ‹è¯•æŸå¤±å‡½æ•°ç»„ä»¶ ===")
    
    # æµ‹è¯•MSEæŸå¤±
    mse_loss = nn.MSELoss()
    pred = torch.tensor([1.0, 2.0, 3.0])
    target = torch.tensor([1.1, 2.1, 2.9])
    mse_result = mse_loss(pred, target)
    print(f"âœ“ MSEæŸå¤±æµ‹è¯•: {mse_result.item():.4f}")
    
    # æµ‹è¯•L2æ­£åˆ™åŒ–
    params = [torch.randn(10, 5), torch.randn(5)]
    reg_loss = sum(torch.norm(param, 2) for param in params)
    print(f"âœ“ L2æ­£åˆ™åŒ–æµ‹è¯•: {reg_loss.item():.4f}")
    
    # æµ‹è¯•æŸå¤±æƒé‡
    lambda_temp = 1.0
    lambda_reg = 0.001
    yolo_loss = 2.0
    temp_loss = 0.5
    reg_loss = 10.0
    
    total_loss = yolo_loss + lambda_temp * temp_loss + lambda_reg * reg_loss
    print(f"âœ“ åŠ æƒæŸå¤±æµ‹è¯•: {total_loss:.4f}")
    print(f"  - YOLO: {yolo_loss}")
    print(f"  - æ¸©åº¦: {lambda_temp} Ã— {temp_loss} = {lambda_temp * temp_loss}")
    print(f"  - æ­£åˆ™: {lambda_reg} Ã— {reg_loss} = {lambda_reg * reg_loss}")

def test_loss_function_improvements():
    """æµ‹è¯•æŸå¤±å‡½æ•°çš„æ”¹è¿›å»ºè®®"""
    print("\n=== æŸå¤±å‡½æ•°æ”¹è¿›å»ºè®® ===")
    
    improvements = [
        "1. æ·»åŠ Focal Lossç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡",
        "2. æ·»åŠ SmoothL1Lossç”¨äºè¾¹ç•Œæ¡†å›å½’",
        "3. å®ç°è‡ªé€‚åº”æƒé‡è°ƒæ•´æœºåˆ¶",
        "4. æ·»åŠ æ¸©åº¦æŸå¤±çš„é²æ£’æ€§å¤„ç†",
        "5. å®ç°æŸå¤±å‡½æ•°çš„å¯è§†åŒ–ç›‘æ§"
    ]
    
    for improvement in improvements:
        print(f"  {improvement}")
    
    # ç¤ºä¾‹ï¼šFocal Losså®ç°
    print(f"\nç¤ºä¾‹ - Focal Losså®ç°:")
    print("""
    class FocalLoss(nn.Module):
        def __init__(self, alpha=1, gamma=2):
            super().__init__()
            self.alpha = alpha
            self.gamma = gamma
            
        def forward(self, inputs, targets):
            ce_loss = F.cross_entropy(inputs, targets, reduction='none')
            pt = torch.exp(-ce_loss)
            focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
            return focal_loss.mean()
    """)
    
    # ç¤ºä¾‹ï¼šSmoothL1Loss
    print(f"\nç¤ºä¾‹ - SmoothL1Lossç”¨äºè¾¹ç•Œæ¡†:")
    print("""
    smooth_l1_loss = nn.SmoothL1Loss()
    bbox_loss = smooth_l1_loss(pred_boxes, gt_boxes)
    """)

def analyze_current_implementation():
    """åˆ†æå½“å‰æŸå¤±å‡½æ•°å®ç°çš„ä¼˜ç¼ºç‚¹"""
    print("\n=== å½“å‰å®ç°åˆ†æ ===")
    
    print("âœ… ä¼˜ç‚¹:")
    print("  1. åŸºæœ¬çš„å¤šä»»åŠ¡æŸå¤±æ¡†æ¶å·²å»ºç«‹")
    print("  2. åŒ…å«æ¸©åº¦å›å½’æŸå¤±å’ŒL2æ­£åˆ™åŒ–")
    print("  3. æ”¯æŒæ¢¯åº¦åå‘ä¼ æ’­")
    print("  4. è¿”å›è¯¦ç»†çš„æŸå¤±åˆ†è§£ä¿¡æ¯")
    
    print("\nâŒ ä¸è¶³:")
    print("  1. ç¼ºå°‘Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡")
    print("  2. æ²¡æœ‰SmoothL1Lossç”¨äºè¾¹ç•Œæ¡†å›å½’")
    print("  3. æƒé‡æ˜¯å›ºå®šçš„ï¼Œç¼ºå°‘è‡ªé€‚åº”è°ƒæ•´")
    print("  4. æ²¡æœ‰å¤„ç†æ¸©åº¦æ•°æ®ç¼ºå¤±çš„æƒ…å†µ")
    print("  5. ç¼ºå°‘æŸå¤±å‡½æ•°çš„éªŒè¯å’Œç›‘æ§")
    
    print("\nğŸ”§ å»ºè®®æ”¹è¿›:")
    print("  1. å®ç°æ›´å®Œæ•´çš„YOLOæŸå¤±å‡½æ•°")
    print("  2. æ·»åŠ æ¸©åº¦æŸå¤±çš„é²æ£’æ€§å¤„ç†")
    print("  3. å®ç°åŠ¨æ€æƒé‡è°ƒæ•´æœºåˆ¶")
    print("  4. æ·»åŠ æŸå¤±å‡½æ•°çš„å¯è§†åŒ–")
    print("  5. å¢åŠ å¼‚å¸¸å¤„ç†å’Œè¾¹ç•Œæ£€æŸ¥")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” æŸå¤±å‡½æ•°å…¨é¢æ£€æŸ¥")
    print("=" * 50)
    
    # æµ‹è¯•å¤šä»»åŠ¡æŸå¤±å‡½æ•°
    success = test_multi_task_loss()
    
    # æµ‹è¯•æŸå¤±ç»„ä»¶
    test_loss_components()
    
    # æµ‹è¯•æ”¹è¿›å»ºè®®
    test_loss_function_improvements()
    
    # åˆ†æå½“å‰å®ç°
    analyze_current_implementation()
    
    print("\n" + "=" * 50)
    if success:
        print("âœ… æŸå¤±å‡½æ•°åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
        print("ğŸ’¡ å»ºè®®æŒ‰ç…§æ”¹è¿›å»ºè®®å®Œå–„å®ç°")
    else:
        print("âŒ æŸå¤±å‡½æ•°å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦ä¿®å¤")
    
    return success

if __name__ == "__main__":
    main()